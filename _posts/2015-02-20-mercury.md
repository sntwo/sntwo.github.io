---
layout: post
title: mercury
tags:
- mercury
- swift
- metal
comments: true
---
Swift and metal have both been around for a while now, and there are plenty of tutorials on how to draw a textured sprite, or a 
rotating cube, or even a particle system powered by Box2d out there, but what about drawing multiple different objects?  This will 
be the first post on hopefully a series about the development of a simple engine to draw with Metal & Swift.  The code is all
in a public repo [here](https://github.com/sntwo/mercury).  Since it is metal, it has to be tested on an actual device (not the 
simulator) that is metal capable.  I'm testing on an iPhone 6.

###Problem 1: getting something on the screen
Just like OpenGL, just getting a specific color to appear on the screen is a huge pain.  Metal is actually better than OpenGL
from a development perspective because lots of errors are actually shown in the debugger, unlike in OpenGL where you have to
know when to call glGetError.  It still requires quite a bit of setup code.  My initial strategy is to have the apps main view
controller setup the metal drawing environment and a rendering loop which will call update and render functions on a scene object,
which will in turn call draw commands on renderable objects it stores.  

####The view controller
As always it all starts at the view controller:

```swift
import Foundation
import UIKit
import QuartzCore
import Metal

class S2ViewController : UIViewController{
  var currentScene: S2SceneNode!
  var device: MTLDevice!
  var metalLayer: CAMetalLayer!
  var timer: CADisplayLink!
  var frameStartTime = CFAbsoluteTimeGetCurrent()
  
  override init() {
    super.init(nibName:nil, bundle:nil)
    device = MTLCreateSystemDefaultDevice()
    metalLayer = CAMetalLayer()
    metalLayer.device = device
    metalLayer.pixelFormat = .BGRA8Unorm
    metalLayer.framebufferOnly = true
    metalLayer.frame = view.layer.frame
    view.layer.addSublayer(metalLayer)
    currentScene = MainScene(controller: self)
    currentScene.run()
    timer = CADisplayLink(target: self, selector: Selector("gameloop"))
    timer.addToRunLoop(NSRunLoop.mainRunLoop(), forMode: NSDefaultRunLoopMode)
  }
  
  func gameloop() {
    let currentTime = CFAbsoluteTimeGetCurrent()
    let frameTime = currentTime - frameStartTime
    frameStartTime = currentTime
    currentScene.update(frameTime)
    currentScene.render()
  }
  
  required init(coder: NSCoder) {
    fatalError("NSCoding not supported")
  }
}
```

Simple enough right?  On init, the controller sets up the metal layer and device, a subclass of our scene, and a gameloop.

####The node graph
I'm going to skip the scene implementation for a second and go straight to the node, subclasses of which will represent 
individual objects to be drawn into the scene.  As such, the node will recieve update and rendering calls passed on by the 
scene, and also define a parent/child hierarchy:

```swift
class S2Node {
  var children = [S2Node]()
  weak var parent:S2Node? = nil
  
  func addChild(child: S2Node){
    children.append(child)
    child.parent = self
  }
  
  func update(dt: NSTimeInterval) {
    for node in children {
      node.update(dt)
    }
  }

  func render(){
    for node in children {
      node.render()
    }
  }
}
```
Each node has on parent and an array of children.  It passes on update and draw calls to its children.

####The scene
Since the scene will have a list of nodes (like a node), and also passes on update and render calls (like a node), I'll steal
a trick I first saw in Sprite Kit and make the scene a special subclass of the node:

```swift
class S2SceneNode : S2Node {
  /// r, g, b, a values that are used to clear the screen before each new frame
  var backgroundColor = (0.0, 1.0, 0.0, 1.0)
  weak var viewController:S2ViewController!
  var commandQueue: MTLCommandQueue!
  
  init(controller:S2ViewController){
    viewController = controller
    commandQueue = viewController.metalLayer.device.newCommandQueue()
    super.init()
  }
  
  func run(){}
  
  override func render() {
    let drawable = viewController.metalLayer.nextDrawable()
    let renderPassDescriptor = MTLRenderPassDescriptor()
    renderPassDescriptor.colorAttachments[0].texture = drawable.texture
    renderPassDescriptor.colorAttachments[0].loadAction = .Clear
    let (r, b, g, a) = self.backgroundColor
    renderPassDescriptor.colorAttachments[0].clearColor = MTLClearColor(red: r, green: g, blue: b, alpha: a)
    let commandBuffer = commandQueue.commandBuffer()
    let renderEncoderOpt = commandBuffer.renderCommandEncoderWithDescriptor(renderPassDescriptor)
    if let renderEncoder = renderEncoderOpt {
      for child in children{
        //child at least needs to set render pipeline state, set buffers, and call a draw primitives
        child.render()
      }
      renderEncoder.endEncoding()
    } 
    commandBuffer.presentDrawable(drawable)
    commandBuffer.commit()
  }
}
```
The interesting part is obviously where the scene overrides the render function.  Since this gets called once per
frame (and for the children - once per child) the way the labor is divided has a large impact on performance.  For a
breakdown see the Metal Programming Guide [explanation](https://developer.apple.com/library/ios/documentation/Miscellaneous/Conceptual/MetalProgrammingGuide/Cmd-Submiss/Cmd-Submiss.html#//apple_ref/doc/uid/TP40014221-CH3-SW1)
of transient and non-transient objects.  Here is the list of non-transient (i.e. do not make one every frame) objects:
- Command queues
- Data buffers
- Textures
- Sampler states
- Libraries
- Compute states
- Render pipeline states
- Depth/stencil states

Hence, the scene stores a MTLCommandQueue (heavy), and every frame grabs a MTLCommandBuffer from that in which to place
its draw commands.  Each commandBuffer is then decorated with a renderPassDescriptor, which basically describes what is 
being rendered to.  In the above code it defines the texture to draw to (given by the CAMetalLayer) and a color to clear
it to.  Finally the scene goes through its list of children and tells them to render before wrapping up the commandBuffer.

It sounds reasonable enough for now, but maybe there is a better way.  For example, the scene could also go on to declare
one pipeline state and force all of the children node to use it (limiting their flexibility, but probably increasing speed).
I don't have a feel for where the tradeoffs in speed are yet.

Anyway, the scene graph is currently empty, but the commandBuffer still works.  Build and run on a device and the blue background
color identified appears:
![Success](https://cloud.githubusercontent.com/assets/2131915/6308903/ff8b8634-b8fc-11e4-82b4-be72da4ab868.PNG)





